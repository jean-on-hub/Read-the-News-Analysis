{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1444518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Are the tf-idf scores the same?\n",
      "0                             YES\n",
      "        Article 1  Article 2  Article 3  Article 4  Article 5  Article 6  \\\n",
      "abbasi          0          0          0          1          0          0   \n",
      "abide           1          0          0          0          0          0   \n",
      "about           0          0          0          0          0          0   \n",
      "accord          0          0          1          0          0          0   \n",
      "add             1          0          0          0          0          0   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "world           0          0          0          0          0          3   \n",
      "would           0          0          0          1          0          0   \n",
      "year            0          1          0          0          0          0   \n",
      "yi              0          0          0          0          0          0   \n",
      "yuan            0          0          0          0          0          0   \n",
      "\n",
      "        Article 7  Article 8  Article 9  Article 10  \n",
      "abbasi          0          0          0           0  \n",
      "abide           0          0          0           0  \n",
      "about           1          0          0           0  \n",
      "accord          0          0          0           0  \n",
      "add             0          0          1           0  \n",
      "...           ...        ...        ...         ...  \n",
      "world           0          0          0           0  \n",
      "would           0          0          1           0  \n",
      "year            0          0          0           0  \n",
      "yi              0          0          0           2  \n",
      "yuan            0          0          0           2  \n",
      "\n",
      "[353 rows x 10 columns]\n",
      "        Article 1  Article 2  Article 3  Article 4  Article 5  Article 6  \\\n",
      "abbasi   0.000000   0.000000   0.000000   2.704748        0.0   0.000000   \n",
      "abide    2.704748   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "about    0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "accord   0.000000   0.000000   2.704748   0.000000        0.0   0.000000   \n",
      "add      2.299283   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "world    0.000000   0.000000   0.000000   0.000000        0.0   8.114244   \n",
      "would    0.000000   0.000000   0.000000   2.299283        0.0   0.000000   \n",
      "year     0.000000   2.704748   0.000000   0.000000        0.0   0.000000   \n",
      "yi       0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "yuan     0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "\n",
      "        Article 7  Article 8  Article 9  Article 10  \n",
      "abbasi   0.000000        0.0   0.000000    0.000000  \n",
      "abide    0.000000        0.0   0.000000    0.000000  \n",
      "about    2.704748        0.0   0.000000    0.000000  \n",
      "accord   0.000000        0.0   0.000000    0.000000  \n",
      "add      0.000000        0.0   2.299283    0.000000  \n",
      "...           ...        ...        ...         ...  \n",
      "world    0.000000        0.0   0.000000    0.000000  \n",
      "would    0.000000        0.0   2.299283    0.000000  \n",
      "year     0.000000        0.0   0.000000    0.000000  \n",
      "yi       0.000000        0.0   0.000000    5.409496  \n",
      "yuan     0.000000        0.0   0.000000    5.409496  \n",
      "\n",
      "[353 rows x 10 columns]\n",
      "        Article 1  Article 2  Article 3  Article 4  Article 5  Article 6  \\\n",
      "abbasi   0.000000   0.000000   0.000000   2.704748        0.0   0.000000   \n",
      "abide    2.704748   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "about    0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "accord   0.000000   0.000000   2.704748   0.000000        0.0   0.000000   \n",
      "add      2.299283   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "world    0.000000   0.000000   0.000000   0.000000        0.0   8.114244   \n",
      "would    0.000000   0.000000   0.000000   2.299283        0.0   0.000000   \n",
      "year     0.000000   2.704748   0.000000   0.000000        0.0   0.000000   \n",
      "yi       0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "yuan     0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "\n",
      "        Article 7  Article 8  Article 9  Article 10  \n",
      "abbasi   0.000000        0.0   0.000000    0.000000  \n",
      "abide    0.000000        0.0   0.000000    0.000000  \n",
      "about    2.704748        0.0   0.000000    0.000000  \n",
      "accord   0.000000        0.0   0.000000    0.000000  \n",
      "add      0.000000        0.0   2.299283    0.000000  \n",
      "...           ...        ...        ...         ...  \n",
      "world    0.000000        0.0   0.000000    0.000000  \n",
      "would    0.000000        0.0   2.299283    0.000000  \n",
      "year     0.000000        0.0   0.000000    0.000000  \n",
      "yi       0.000000        0.0   0.000000    5.409496  \n",
      "yuan     0.000000        0.0   0.000000    5.409496  \n",
      "\n",
      "[353 rows x 10 columns]\n",
      "Article 1    fare\n",
      "dtype: object\n",
      "Article 2    hong\n",
      "dtype: object\n",
      "Article 3    sugar\n",
      "dtype: object\n",
      "Article 4    petrol\n",
      "dtype: object\n",
      "Article 5    engine\n",
      "dtype: object\n",
      "Article 6    australia\n",
      "dtype: object\n",
      "Article 7    car\n",
      "dtype: object\n",
      "Article 8    railway\n",
      "dtype: object\n",
      "Article 9    cabinet\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from articles import articles\n",
    "from preprocessing import preprocess_text\n",
    "\n",
    "# import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer\n",
    "\n",
    "# view article\n",
    "# print(articles[0])\n",
    "\n",
    "# preprocess articles\n",
    "processed_articles = [preprocess_text(article) for article in articles]\n",
    "\n",
    "\n",
    "# initialize and fit CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "# convert counts to tf-idf\n",
    "\n",
    "counts = vectorizer.fit_transform(processed_articles)\n",
    "transformer = TfidfTransformer(norm = None)\n",
    "tfidf_scores_transformed = transformer.fit_transform(counts)\n",
    "# initialize and fit TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm = None)\n",
    "tfidf_scores = vectorizer.fit_transform(processed_articles)\n",
    "# check if tf-idf scores are equal\n",
    "\n",
    "\n",
    "if np.allclose(tfidf_scores_transformed.todense(), tfidf_scores.todense()):\n",
    "  print(pd.DataFrame({'Are the tf-idf scores the same?':['YES']}))\n",
    "else:\n",
    "  print(pd.DataFrame({'Are the tf-idf scores the same?':['No, something is wrong :(']}))\n",
    "\n",
    "\n",
    "# get vocabulary of terms\n",
    "try:\n",
    "  feature_names = vectorizer.get_feature_names()\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# get article index\n",
    "try:\n",
    "  article_index = [f\"Article {i+1}\" for i in range(len(articles))]\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# create pandas DataFrame with word counts\n",
    "try:\n",
    "  df_word_counts = pd.DataFrame(counts.T.todense(), index=feature_names, columns=article_index)\n",
    "  print(df_word_counts)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# create pandas DataFrame(s) with tf-idf scores\n",
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores_transformed.T.todense(), index=feature_names, columns=article_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores.T.todense(), index=feature_names, columns=article_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# get highest scoring tf-idf term for each article\n",
    "for i in range(1,10):\n",
    "  print(df_tf_idf[[f'Article {i}']].idxmax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcbb987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jdalm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "756de2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jdalm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f91e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jdalm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087bcab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
